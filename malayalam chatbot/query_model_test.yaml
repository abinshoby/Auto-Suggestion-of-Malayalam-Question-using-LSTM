backend: theano
class_name: Model
config:
  input_layers:
  - [input_1, 0, 0]
  layers:
  - class_name: InputLayer
    config:
      batch_input_shape: !!python/tuple [null, 100]
      dtype: int32
      name: input_1
      sparse: false
    inbound_nodes: []
    name: input_1
  - class_name: Embedding
    config:
      activity_regularizer: null
      batch_input_shape: !!python/tuple [null, 100]
      dtype: float32
      embeddings_constraint: null
      embeddings_initializer:
        class_name: RandomUniform
        config: {maxval: 0.05, minval: -0.05, seed: null}
      embeddings_regularizer: null
      input_dim: 50
      input_length: 100
      mask_zero: false
      name: embedding_1
      output_dim: 300
      trainable: true
    inbound_nodes:
    - - - input_1
        - 0
        - 0
        - {}
    name: embedding_1
  - class_name: Bidirectional
    config:
      layer:
        class_name: LSTM
        config:
          activation: tanh
          activity_regularizer: null
          bias_constraint: null
          bias_initializer:
            class_name: Zeros
            config: {}
          bias_regularizer: null
          dropout: 0.0
          go_backwards: false
          implementation: 1
          kernel_constraint: null
          kernel_initializer:
            class_name: VarianceScaling
            config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
          kernel_regularizer: null
          name: lstm_1
          recurrent_activation: hard_sigmoid
          recurrent_constraint: null
          recurrent_dropout: 0.0
          recurrent_initializer:
            class_name: Orthogonal
            config: {gain: 1.0, seed: null}
          recurrent_regularizer: null
          return_sequences: true
          return_state: false
          stateful: false
          trainable: true
          unit_forget_bias: true
          units: 100
          unroll: false
          use_bias: true
      merge_mode: concat
      name: bidirectional_1
      trainable: true
    inbound_nodes:
    - - - embedding_1
        - 0
        - 0
        - {}
    name: bidirectional_1
  - class_name: Bidirectional
    config:
      layer:
        class_name: LSTM
        config:
          activation: tanh
          activity_regularizer: null
          bias_constraint: null
          bias_initializer:
            class_name: Zeros
            config: {}
          bias_regularizer: null
          dropout: 0.0
          go_backwards: false
          implementation: 1
          kernel_constraint: null
          kernel_initializer:
            class_name: VarianceScaling
            config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
          kernel_regularizer: null
          name: lstm_2
          recurrent_activation: hard_sigmoid
          recurrent_constraint: null
          recurrent_dropout: 0.0
          recurrent_initializer:
            class_name: Orthogonal
            config: {gain: 1.0, seed: null}
          recurrent_regularizer: null
          return_sequences: false
          return_state: false
          stateful: false
          trainable: true
          unit_forget_bias: true
          units: 100
          unroll: false
          use_bias: true
      merge_mode: concat
      name: bidirectional_2
      trainable: true
    inbound_nodes:
    - - - bidirectional_1
        - 0
        - 0
        - {}
    name: bidirectional_2
  - class_name: Dense
    config:
      activation: softmax
      activity_regularizer: null
      bias_constraint: null
      bias_initializer:
        class_name: Zeros
        config: {}
      bias_regularizer: null
      kernel_constraint: null
      kernel_initializer:
        class_name: VarianceScaling
        config: {distribution: uniform, mode: fan_avg, scale: 1.0, seed: null}
      kernel_regularizer: null
      name: dense_1
      trainable: true
      units: 5
      use_bias: true
    inbound_nodes:
    - - - bidirectional_2
        - 0
        - 0
        - {}
    name: dense_1
  name: model_1
  output_layers:
  - [dense_1, 0, 0]
keras_version: 2.2.0
